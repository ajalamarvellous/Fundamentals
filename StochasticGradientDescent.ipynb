{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhri9JdpJOiLU/E62U1/IJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajalamarvellous/Fundamentals/blob/main/StochasticGradientDescent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iECSZXwh7BNZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "mmt_ebDlMKzJ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSGDClassifier(object):\n",
        "  \"\"\"This is a custom stochastic gradient descent being built from numpy only\"\"\"\n",
        "  def __init__(self, iterations, batch_size, lr):\n",
        "    self._iterations = iterations\n",
        "    self._batch_size = batch_size\n",
        "    self._lr = lr\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self._w = np.random.randn(X.shape[1])\n",
        "    self._b = np.random.randn()\n",
        "    for iter in range(self._iterations):\n",
        "      batch_mask = np.random.choice(len(X), self._batch_size)\n",
        "      y_hat = self.predict(X[batch_mask])\n",
        "      loss = self._loss(y[batch_mask], y_hat)\n",
        "      self._update_weights(loss)\n",
        "\n",
        "  def predict(self, X):\n",
        "    return self._sigmoid(X @ self._w.T + self._b)\n",
        "\n",
        "  def _sigmoid(self, X):\n",
        "    return 1 / (1 + np.exp(-X))\n",
        "\n",
        "  def _loss(self, y, y_hat):\n",
        "    return -np.sum((y * np.log(y_hat)) + ((1 - y) * np.log(1 - y_hat))) / len(y)\n",
        "\n",
        "  def _update_weights(self, loss):\n",
        "    self._w -= self._lr * loss\n",
        "    self._b -= self._lr *loss\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q0SfkdC08Ed3"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c9lPYxo0-e7e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}